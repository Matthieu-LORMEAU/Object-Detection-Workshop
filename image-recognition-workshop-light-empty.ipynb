{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The true story behind object recognition algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://media.giphy.com/media/LR6yJOEv7gQVA3Oksq/giphy.gif\" width=\"800\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object recognition is one of machine learning big successes. The progress that we have made in this field is enhancing many industries and innovations, such as self driving cars, text recognition, medicine tools, face identification (apple's face id) etc.\n",
    "\n",
    "### How does it work ?\n",
    "\n",
    "Through this notebook, you will discover how it all started and the basics of image recognition.\n",
    "\n",
    "- first, you will get to know the main ideas behind the algorithms.\n",
    "\n",
    "- then, you will implement a digit recognition algorithm.\n",
    "\n",
    "- finally, you will use a state of the art object recognition model to detect cars and buses in the images you brought to this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use this notebook\n",
    "\n",
    "This notebook is composed of cells :\n",
    "- some cells contain textual explanations\n",
    "- some cells contain code\n",
    "\n",
    "You will advance in this notebook by reading the text cells and **running the code cells**. To run a code cell, you need to select it and hit the **&#9658; Run** button at the top.\n",
    "\n",
    "**Some cells are incomplete ; you will need to complete them before running them**. \n",
    "<br/>These incomplete cells are explicitly marked with a    **# _--------------------------TO DO-------------------------_**    header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<div style=\"text-align:center; font-weight : bold; font-size : 1.25em\">Table of contents</div>\n",
    "<br>\n",
    "\n",
    "1. Neural networks and why we created them\n",
    "2. Convolutional neural networks (CNN)\n",
    "3. Creating a handwritten digit recognition CNN\n",
    "4. Using a pre-trained state of the art model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 What is a neural network ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on nature, an artificial neural network is a **set of connected units or nodes (called neurons)**, that form a network as a whole.\n",
    "\n",
    "The operation of a complete neural network is straightforward : we enter variables as inputs, and after some calculations, an output is returned.\n",
    "\n",
    "For example, inputs could me measurements about a person's body, and the output whether it's a woman or a man (of course, a neural network would be overkill for that application).\n",
    "\n",
    "Artificial neural networks are usually **represented as layers of neurons**, where the neurons of one layer are connected to the following layer. <br> Each connection between two neurons has a **weight** (for example 0.65, -1.2, 3.4 ...).\n",
    "\n",
    "This is a representation of a neural network:\n",
    "\n",
    "<img style=\"float: left;margin-right:40px\" src=\"images/pt1-nn/med_nn.png\" width=\"50%\" >\n",
    "\n",
    "<br> \n",
    "\n",
    "Neural networks can usually be read from left to right : \n",
    "\n",
    "- &nbsp; the first layer is the layer in which inputs are entered.\n",
    "- &nbsp; in the middle, we have hidden layers (2 in this example) : hidden layers are basically layers between the inputs and the outputs.\n",
    "- &nbsp; the last layer contains the outputs\n",
    "\n",
    "Note that the +1 neurons are the equivalent of a standalone constant in a mathematical function, for example $a$ in $f(x) = a + bx + cx²$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 What does a neuron do ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neurons are **inspired from biological neurons' cells**.\n",
    "\n",
    "Here is how biological neurons work :\n",
    "\n",
    "<img style=\"float: left; margin-right : 40px\" src=\"images/pt1-nn/bio_neuron.PNG\" width=\"50%\" >\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "- each neuron has dendrites which **receive incoming signals** sent by other neurons. <br><br>\n",
    "-  If the neuron receives a **high enough** level of signals, the neuron sends an **electrical pulse into the terminals** which are received by the following neurons. Note the \"high enough level of signal\" part, which is very important. This is what allows our brain to be so flexible and adapt to any problem.\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "<img style=\"float: right;margin-right:100px\" src=\"images/pt1-nn/neuron.PNG\" width=\"40%\" >\n",
    "\n",
    "An artificial neuron behaves similarly :\n",
    "\n",
    "- a neuron sums all the inputs multiplied by the weights of the connections\n",
    "> $1 * \\theta_{0} + x_{1} * \\theta_{1} + x_{2} * \\theta_{2} + x_{3} * \\theta_{3}$\n",
    "- the neuron applies a **non-linear function**, called **activation function**, to the sum: \n",
    "> $output = f(1 * \\theta_{0} + x_{1} * \\theta_{1} + x_{2} * \\theta_{2} + x_{3} * \\theta_{3})$\n",
    "\n",
    "<br><br><br><br>\n",
    "This non-linear function is the equivalent of the \"**high enough** level of signals\" part for the biological neurons. The activation function basically determines if the neuron transmits the information to the following neurons or not.  For example, a basic non-linear activation function is:\n",
    "- if output > 0, transmit output\n",
    "- if output <= 0, transmit nothing\n",
    "\n",
    "Actually, this basic non-linear function is one of the most used non-linear activation functions and is called the ReLu (Rectified Linear Unit) activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 How does a neural network learns to make predictions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that a neural network is basically _input - linked layers of neurons - output_ , the remaining question is :\n",
    "\n",
    "**How do we get a neural network to do what we want it to do?**\n",
    "\n",
    "1. We choose an input for our network.\n",
    "2. We choose an output for our network.\n",
    "3. We train the network to predict the correct output for any input : training the network means adjusting the weights of the connections between the neurons. On the following image, the weights are $\\theta_{0}, \\theta_{1}, ..., \\theta_{n-1}, \\theta_{n}$ :\n",
    "\n",
    "<img src=\"images/pt1-nn/neuron.PNG\" width=\"450px\" >\n",
    "\n",
    "\n",
    "The adjustment of the weights is automatic and works the same as when we, humans, train to learn something new.\n",
    "\n",
    "Imagine you are training to learn to shoot a basketball. <br>\n",
    "\n",
    "You take a first try :\n",
    "\n",
    "- the orange basketball represents your shot.\n",
    "- the transparent green ball represents what you try to achieve.\n",
    "\n",
    "<img style=\"float: left;margin-right:40px\" src=\"images/pt1-nn/b1.png\" width=\"50%\" >\n",
    "\n",
    "The total error of your shot is the distance between what you aim for and where your shot lands. Your goal is to minimize this total error. The total error can be written as:\n",
    "\n",
    "$ totalError = \\sqrt{(x_{try} - x_{desired})^2 + (y_{try} - y_{desired})^2 } = \\sqrt{(34 - 0)^2 + (-22 - 0)^2 } = 40.5 cm$\n",
    "\n",
    "This total error is made of the error along the $x$ axis and the error along the $y$ axis. In order to reduce the total error, you must reduce the sub-errors along $x$ and $y$. \n",
    "\n",
    "This is how we did on our first shot :\n",
    "\n",
    "- $xError = x_{try} - x_{desired} = 34 - 0 = 34 cm$\n",
    "- $yError = y_{try} - y_{desired} = (-22) - 0 = -22 cm$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "As a result, we will adjust our aim slightly towards the left and add some strength. **We adapted our behavior according to our error in order to reduce the error in the next shot**.\n",
    "\n",
    "We focus hard and take another shot.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<img src=\"images/pt1-nn/math_meme.webp\">\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<img style=\"float: left;margin-right:40px\" src=\"images/pt1-nn/b2.png\" width=\"50%\" >\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "- $ totalError = \\sqrt{(18 - 0)^2 + (15 - 0)^2 } = 23.5 cm \\rightarrow$ our second shot is significantly better. **We're improving**.\n",
    "<br><br>\n",
    "- $xError = x_{try} - x_{desired} = 18 - 0 = 18 cm \\rightarrow$ adjust again towards the left\n",
    "<br><br>\n",
    "- $yError = y_{try} - y_{desired} = 15 - 0 = 15 cm \\rightarrow$ reduce our strength slightly\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "Finnaly, we score our first shot:\n",
    "\n",
    "<img style=\"float: left;margin-right:40px\" src=\"images/pt1-nn/b4.png\" width=\"50%\" >\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "The training of an artificial neural network is **very similar to this example**.\n",
    "\n",
    "The main difference is that we, humans, train much faster because we have intuition and generalize our knowledge much better. Artificial **neural network don't have any intuition**:\n",
    "\n",
    "> if a human takes his first try ever at shooting a basketball, it will not fall far from the net. Maybe 50 cm away at most.<br> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $\\neq$<br>\n",
    ">if a machine with a neural network takes its first try ever at shooting a basketball, the ball will land on Mars.\n",
    "\n",
    "**Hence, a neural network needs to experiment a lot before it is trained and has good performance on unknown data.**\n",
    "\n",
    "A neural network requires at least **10 000 samples** (different inputs) in order to be trained. **The more data we have, the better our neural network will be**.<br>\n",
    "This is the reason why **gathering data is so crucial nowadays** : our models' performance depends on it.\n",
    "\n",
    "Now that you understand the concept of training according to the error, we can sum up how a neural network trains :\n",
    "\n",
    ">Until the neural network has good performance, repeat:\n",
    ">- feed a new input\n",
    ">- compute the error for this input\n",
    ">- adjust the weights $\\theta_{0}, \\theta_{1}, ..., \\theta_{n-1}, \\theta_{n}$\n",
    "\n",
    "At the end of training, the combination of the $\\theta$ weights in the network is close to optimality and allows to make good predictions on most new unknown inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Convolutional neural networks\n",
    "\n",
    "<br>\n",
    "\n",
    "Before starting this workshop, you surely had heard of neural networks. But had you heard of **convolutional neural networks** ?\n",
    "Convolutional neural networks are currently the **most popular AI models for object detection / recognition** because they achieve by far the best results in this field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the pioneers of convolutional neural networks is **Yann LeCun**, a French researcher.\n",
    "\n",
    "In 1998, Yann LeCun and his collaborators at AT&T Labs were experimenting with a large range of machine learning solutions for **handwritten digits recognition**.<br>\n",
    "In this context, they developed **the first convolutional neural network architecture, which was named LeNet** (LeCun + neural network).\n",
    "\n",
    "LeNet was a huge success and was soon used by many banks for automatic bank checks recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Convolutional Neural Network (CNN)** is a special kind of multi-layer neural network, designed to recognize visual patterns directly from images.\n",
    "\n",
    "||\n",
    "|:-|:-|\n",
    "|input|image|\n",
    "|processing|convolutional neural network|\n",
    "|output|label that best fits the image content among the labels that we chose|\n",
    "\n",
    "**Example :**\n",
    "\n",
    "Handwritten digit recognition.\n",
    "\n",
    "||\n",
    "|:-|:-|\n",
    "|input|image with a written digit|\n",
    "|processing|convolutional neural network|\n",
    "|output|probabilities for the digit to be 0, 1, 2, 3, 4, 5, 6, 7, 8 or 9. The predicted output is the digit with the highest probability|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The input : how to pass an image to a neural network ?"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computers, an image is represented by **3 pixel layers** (RED, GREEN, BLUE → **RGB**) :\n",
    "\n",
    "Each layer is a 2D matrix with **values between 0 and 255** :\n",
    "- 0 is black\n",
    "- 255 is the color (red, green or blue) at its most pronounced level\n",
    "\n",
    "When we stack the 3 layers, we obtain a 3-dimensional matrix.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "We can use this 3-D matrix as the input of a convolutional neural network, or decide to convert our images to grey scaled images if the colors are irrelevant. <br>\n",
    "Grey scaled images have a **single layer of pixels** (2-D matrix) compared to colored images.\n",
    "\n",
    "In part 3. of this workshop, you will implement a digit recognition CNN that uses grey scaled images as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The structure of a CNN : how is it special compared to a regular neural networks ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at a picture, our eyes look for **features** such as certain shapes or objects that we know in order to understand the picture. \n",
    "\n",
    "However, at the most basic level, shapes are composed of curves, edges, circles, squares etc. Our eyes are used to detect those basic shapes and we don't need to think about it, but this knowledge isn't granted for a computer.\n",
    "\n",
    "A computer is able to perform object recognition by looking for **low level features such as edges and curves**, and then building up to more **abstract concepts**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get an intuition of how convolutional neural networks work, this short extract from an AI conference clearly explains the concept :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"images/pt2-cnn/cnn_conf.mp4\" width=\"95%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Source : https://www.youtube.com/watch?v=Oqm9vsf_hvU_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the video, different types of layers are used in a convolutional neural network  : **these special layers are what differentiates convolutional neural networks from regular neural networks**.\n",
    "\n",
    "#### 2.2.1 Convolution layers\n",
    "\n",
    "The goal of the convolution layers is to **identify the features**. Features are simple in the first layers and keep increasing in complexity as we keep adding convolutional layers : \n",
    "- in the first convolution layers, edges, curves, lines are detected <br>\n",
    "- as we keep adding convolution layers, shapes (circle, square...) are detected <br>\n",
    "- in the last convolution layers, objects (cat, chair, pizza...) are finally detected\n",
    "\n",
    "<img src=\"images/pt2-cnn/low_high_features.png\" width=\"85%\">\n",
    "\n",
    "<br>\n",
    "\n",
    "**&#8594; How do these convolution layers detect shapes ?**\n",
    "\n",
    "As explained in the video, each convolution layer has **a certain number of filters** ; the number of filters and their size is **chosen by the user** who designs the CNN. \n",
    "<br>Each filter **identifies the presence (or absence) of patterns by scanning the whole image** and outputting a **feature map**.\n",
    "<br><br>\n",
    "\n",
    "<img src=\"images/pt2-cnn/filter_scan.gif\" style=\"float:left\" width = \"45%\">\n",
    "<img src=\"images/pt2-cnn/filter_maths.png\" style=\"float:right\" width = \"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Pooling layers\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/pt2-cnn/avg_max_pooling.png\" style=\"float:right; margin-right:10%; margin-left:10%\" width = \"27%\">\n",
    "\n",
    "<br>\n",
    "\n",
    "A pooling layer is another building block of a CNN. Pooling is also called **subsampling**.\n",
    "\n",
    "Its function is to progressively **reduce the matrix size** to lower the amount of parameters and computation in the network.\n",
    "\n",
    "Pooling layers are not essential if the input of the network is small enough or if we have enough computational power. However, they are used most of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Dropout layers\n",
    "\n",
    "<br>\n",
    "\n",
    "Dropout layers are used to avoid overfitting.\n",
    "\n",
    "**What is overfitting ?**\n",
    "\n",
    "We say a model is overfitted when it performs very well on the training data and poorly on unknown data (samples that were not used to train the model but that the model is supposed to do well on).\n",
    "\n",
    "To get a better intuition of what that means, let's take two concretes examples where overfitting could happen.\n",
    "\n",
    "**Example 1**\n",
    "\n",
    "Imagine we're building a CNN to recognize cats. \n",
    "\n",
    "The CNN is trained with this data :\n",
    "\n",
    "<img src=\"images/pt2-cnn/cat-1.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-2.jfif\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-3.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-4.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "During the training, the CNN will assign weights to some features such as eyes, ears, paws, face, body shape etc.\n",
    "Our CNN is now trained and can recognize and locate the cat on the above pictures.\n",
    "\n",
    "Now we show him some new pictures to see if it works equally well on new data.\n",
    "\n",
    "<img src=\"images/pt2-cnn/cat-5.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-6.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-7.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-8.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "\n",
    "<br><br><br><br><br><br><br><br>\n",
    "\n",
    "Our CNN **doesn't recognize any of these cats**. Why ? It is not used to recognize cats turning away from the camera or who are laying down on floor etc.\n",
    "\n",
    "Our CNN performs poorly on new data because our **training data was too specific**. In our training pictures, all the cats were facing the camera and we would clearly distinguish their face. <br><br> **&#8594; our model is overfitted**.\n",
    "\n",
    "**Example 2**\n",
    "\n",
    "We learnt from our lesson and added some training data. We now have **variety** in our training pictures.\n",
    "\n",
    "<img src=\"images/pt2-cnn/cat-1.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-2.jfif\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-3.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-4.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-5.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-6.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-7.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "<img src=\"images/pt2-cnn/cat-8.jpg\" style=\"float:left; margin-right:5%;\" width = \"20%\">\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "Our model is trained. Cool.\n",
    "\n",
    "Now we pass this picture to our trained CNN:\n",
    "\n",
    "<img src=\"images/pt2-cnn/cat-cropped.jpg\">\n",
    "\n",
    "Damn it ! our model doesn't recognize it. Why ? \n",
    "\n",
    "**Our model probably relies too much on certain features** such as eyes, ears by assigning big weights (high importance) to those and low weights (low importance) to other features. If we want all features to be taken into account, we need to use **dropout layers**.\n",
    "\n",
    "**What is dropout ?**\n",
    "\n",
    "**Dropout** consists into randomly removing a fraction of the neurons in a layer each time we pass a training sample.\n",
    "We decide what fraction of neurons we want to remove.\n",
    "\n",
    "<img src=\"images/pt2-cnn/dropout.PNG\" width=\"80%\">\n",
    "\n",
    "**Note**: the removed neurons are not definitely removed ! each time we use a new training sample, we put all our neurons back and remove a new random set of the neurons. <br>\n",
    "If we consider the above network, maybe the first sample will be trained with h1, h3, h4, the second sample with h2, h4, h5, the third sample with h1, h2, h5 etc.\n",
    "\n",
    "Basically removing a fraction of the neurons is equivalent to removing features. We're telling our neural network:\n",
    "\n",
    "\"Ok now you need to recognize the cat but you can't see his ears neither his legs. Next time you will see his ears and legs but not the nose. etc etc ...\"\n",
    "\n",
    "Dropout is very relevant in CNNs because layers at the end of the network correspond to high level features (as we saw in **2.2.1**). Applying dropout at the end of our CNN is equivalent to removing certain high level features and still make a decision with the remaining features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 General structure of a convolutional neural network.\n",
    "\n",
    "As seen in the video, a convolutional neural network is an assembly of **successive convolution - pooling layers, followed by regular layers of neurons at the end:**\n",
    "\n",
    "- The convolution-pooling layers form the feature learning part of the network.<br><br>\n",
    "- The identified features (nose, wheels, paw, legs, hands...) are then used by regular layers of neurons to classify what the input was (cat, dog, car, person ...)\n",
    "\n",
    "Here is an example of a convolutional neural network whose **input is a handwritten digit image** and the **output are the probabilities of the input being each digit**:\n",
    "<br><br>\n",
    "\n",
    "<img src=\"images/pt2-cnn/cnn_layers.png\" width=\"90%\" >\n",
    "\n",
    "<br><br>\n",
    "\n",
    "The transition between the feature learning part and the classification part is made by a **flattening layer**, whose only purpose is to transform the 2D feature maps into a single vector :\n",
    "\n",
    "<img src=\"images/pt2-cnn/flatten.png\" width=\"20%\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Creating a handwritten digit recognition CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have the required knowledge to build your first convolutional neural network !\n",
    "\n",
    "In this section, you will create a CNN capable of recognizing handwritten digits. This is usually the starting point for every machine learning engineer who dives into object recognition.\n",
    "\n",
    "We will evaluate our neural network on the well-known [MNIST dataset](http://yann.lecun.com/exdb/mnist/). The dataset was created by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models. \n",
    "\n",
    "Each instance corresponds to the image of a digit taken from a scanned document. Each image is a 28 by 28 pixel square (784 pixels total). The dataset is split into a training set consisting of 60,000 images and a test set of 10,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop you will use the Python language with some python libraries to build your neural network :\n",
    "- python is the most popular language for deep learning\n",
    "- **libraries** are powerful and efficient (fast) tools created by the community that allow us to write very little code to perform complex actions. \n",
    "\n",
    "The libraries that we will be using are :\n",
    "\n",
    "|Library &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;|Description &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;|Usual acronym inside code &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;|\n",
    "|:--|:--|:--|\n",
    "|numpy|fast mathematical computation (used by pandas and many other libraries) library|np|\n",
    "|matplotlib|plot library|plt|\n",
    "|tensorflow|deep learning (deep learning = neural networks) library developed by google||\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare the environment and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to load the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to import and load the MNIST dataset.\n",
    "\n",
    "**Note : we will only use 10% of the training data as the website hosting this workshop isn't very powerful ; it would take too long to train our network on 60 000 samples so we will only use 6 000.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_train, y_train) = (x_train[0:6000,:,:], y_train[0:6000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 4 objects :\n",
    "\n",
    "- x_train contains the **training samples** (images of digits)\n",
    "- y_train contains the correct outputs for each training sample (whether each image is a 0,1,...,8,9)<br><br>\n",
    "\n",
    "- x_test contains the **test samples**\n",
    "- y_test contains the correct outputs for the test samples\n",
    "\n",
    "The data is split in training data and testing data because we want to see if what our neural network learns from the training data generalizes well into unknown test data (= avoid overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view some of our training samples to understand what our images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "for i in range(0,16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Preprocess input data for Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images have dimensions. For example : \n",
    "\n",
    "- a full-color 720p image with all 3 RGB channels will have the following dimensions : 1280, 720, 3 (width, height, depth)\n",
    "- a greyscaled image 480p will have the following dimensions : 720, 480, 1 (width, height, depth)\n",
    "\n",
    "In order for Tensorflow to work, our input images must have **valid dimensions**. Valid dimensions for tensorflow means that the **width**, the **height** and the **depth must be explicit**. \n",
    "\n",
    ">(720,480) isn't explicit (the depth is implicit) (720,480,1) is explicit.\n",
    "\n",
    "As a result, we will check the current format of our input data, to see if it matches Tensorflow standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show the data, you can use the ``print`` function. \n",
    "\n",
    "Syntax is ``print(something)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Show x_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Show x_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so it seems that our data is composed of 3 levels of nested arrays of numbers. We would like to get the dimensions of those arrays to see if the 3 dimensions (width, height, depth) are explicit. Use the ``.shape`` attribute to get the dimensions of the data. \n",
    "\n",
    "Syntax is ``something.shape``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Show the dimensions x_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Show the dimensions x_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current shape of our input data is (6000, 28, 28) for x_train and (10000, 28, 28) for x_test.\n",
    "\n",
    "From these results, we can confirm that:\n",
    "\n",
    "- we have 6000 samples of training data and 10000 samples of testing data as expected\n",
    "- each image is of size 28 pixels by 28 pixels\n",
    "- **the depth isn't explicitly stated**, otherwise the shapes would be (6000, 28, 28, 1) and (10000, 28, 28, 1)\n",
    "\n",
    "We need to add this last dimension matching the depth to both x_train and x_test. To achieve that you will need to use the ``reshape`` function.\n",
    "\n",
    "Syntax is ``something.reshape(dimension_1,dimension_2,...,dimension_n)``\n",
    "\n",
    "**Attention : in python as in many programming languages, in order to modify an object, you need to assign a new value to it. Assignment is done with the = sign.**\n",
    "\n",
    "Example : Imagine you have ``x = 3`` and you want to add 5 to ``x``. Doing ``x + 5`` won't change ``x``. If you want to change ``x`` to a new value you need to do ``x = x + 5``\n",
    "\n",
    "If you struggle with this question, ask for help to the instructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add a last dimension to x_train\n",
    "\n",
    "\n",
    "# Add a last dimension to x_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if changes were applied correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great our data now has the correct shape.\n",
    "\n",
    "When using neural networks, we also want to normalize our input data. Normalizing data means scaling all the values between 0 and 1.\n",
    "\n",
    ">Example : 1, 3, 5 &#8594; 0, 0.5, 1\n",
    "\n",
    "To normalize values, the mathematical operation is : \n",
    "\n",
    "$\\Large{x = \\frac{x - x_{min}}{x_{max} - x_{min}}}$\n",
    "\n",
    "In the example above, 3 is normalized by doing $\\frac{3 - 1}{5 - 1} = 0.5$\n",
    "\n",
    "Now normalize ``x_train`` and ``x_test``. You can retrieve the max and min values from an array by doing ``something.max()`` and ``something.min()``.\n",
    "\n",
    "Also you can apply mathematical operations to arrays directly. For example, imagine we have an array ``a = [4, 2, 3]``. Doing ``a = a + 10`` works and ``a`` will now be equal to ``[14, 12, 13]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Normalize x_train\n",
    "\n",
    "\n",
    "# Normalize x_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Preprocess output data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what our output vectors  ``y_train`` and ``y_test`` look like.\n",
    "\n",
    "Print them as well as their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Print y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Print y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Show y_train's shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Show y_test's shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently our output vectors are 1D arrays with digits between 0 and 9 for each sample.<br>\n",
    "\n",
    "However, the usual way of classifying data in neural networks is to **output probabilities between 0 and 1 for each possible output class (each possible digit in our case)**. Therefore the output of our CNN for one input image will be a vector of size 10 :\n",
    "\n",
    "[$p_0$  $p_1$  $p_2$  $p_3$ $p_4$ $p_5$ $p_6$ $p_7$ $p_8$ $p_9$]\n",
    "\n",
    "where $p_x$ is the probability that the input image is the digit $x$.\n",
    "\n",
    "Remember that the goal of a neural network is to **minimize the error** between **predicted output and desired output**.\n",
    "With the current format of ``y_train`` and ``y_test``, we can't compute errors with our output vectors of probabilities.\n",
    "\n",
    "**Example :** \n",
    "<br><br>\n",
    "<div style=\"margin-left : 40px\">\n",
    "            \n",
    "Imagine the input is an image of the digit 2 and we get this output vector of probabilities : \n",
    "\n",
    ">``[0.02  0.03  0.65  0.05  0.01  0.09  0.1  0.01  0.03  0.01]``\n",
    "\n",
    "How do you compute the error between 2 and this vector ? Subtract 2 from every probability ? No that makes no sense.\n",
    "\n",
    "So the question is : how do we transform 2 in the desired vector of probabilities ?<br>\n",
    "As you might have guessed, the desired vector of probabilities for 2 is :\n",
    "\n",
    "> ``[0  0  1  0  0  0  0  0  0  0]``\n",
    "\n",
    "Now we can compute the error between the predicted probabilities and the desired probabilities for digit 2:\n",
    "\n",
    "$E_{0} = 0.02 - 0 = 0.02$<br>\n",
    "$E_{1} = 0.03 - 0 = 0.03$<br>\n",
    "$E_{2} = 0.65 - 1 = -0.35$<br>\n",
    "...<br>\n",
    "$E_{8} = 0.03 - 0 = 0.03$<br>\n",
    "$E_{9} = 0.01 - 0 = 0.01$<br>\n",
    "            \n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "**As a result, we need to transform ``y_train`` and ``y_test``** :\n",
    "\n",
    "<img src=\"images/pt3-mnist/one-hot.png\">\n",
    "\n",
    "Fortunately, there is a premade function in Tensorflow ``keras.utils.to_categorical`` to do this transformation.\n",
    "\n",
    "Syntax is ``keras.utils.to_categorical(something, number_of_classes)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# convert y_train and y_test to the new output format\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Build the convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is a powerful python library that allows us to build neural networks very easily. Run the following code imports the tools that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a summary of the objects that we will use:\n",
    "\n",
    "|Object &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;|Description &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;|\n",
    "|:--|:--|\n",
    "|Sequential|Object containing the whole neural network. We will add the layers to it.|\n",
    "|Conv2D|function to create a convolutional layer|\n",
    "|MaxPooling2D|function to create a max-pooling layer|\n",
    "|Flatten|function to flatten the feature maps|\n",
    "|Dense|function to create a fully connected layer to the previous one|\n",
    "\n",
    "We start by initializing the neural network by creating the sequential object that will store our layers.\n",
    "\n",
    "To initialize the neural network, the syntax is :\n",
    "\n",
    "``your_model_name = Sequential()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Initialize the neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add layers to our neural network. To add layers, the syntax will always be the same :\n",
    "\n",
    "``your_model_name.add(a_new_layer)``\n",
    "\n",
    "``a_new_layer`` could be a Conv2D, a MaxPooling2D, a Dense, a Flatten etc. We will tell you the correct syntax for using each type of layer.\n",
    "\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape.\n",
    "\n",
    "Add a first convolutional layer with **32 filters** of size **3 by 3**, a '**relu**' activation function and an **input shape matching the shape of our input images**.\n",
    "\n",
    "Example:\n",
    "\n",
    "``model.add(Conv2D(filters = 10, \n",
    "                    kernel_size = (2, 2), \n",
    "                    activation =  'tanh', \n",
    "                    input_shape = (16, 16, 3)))``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add the first convolutional layer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a max pooling layer of size 2 x 2.\n",
    "\n",
    "Syntax for creating a MaxPooling2D is:\n",
    "\n",
    "> ``MaxPooling2D(pool_size = (4, 4))``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add a max pooling layer of size 2x2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a second convolutional layer with **64 filters** of size **2 by 2**  and a '**relu**' activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add the second convolutional layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a max pooling layer of size 2 x 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add a max pooling layer of size 2x2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a flattening layer.\n",
    "\n",
    "Syntax for creating a flattening layer is:\n",
    "\n",
    "> ``Flatten()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add a flattening layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a **fully connected layer** with **128 neurons** and a **'relu' activation function**.\n",
    "\n",
    "Syntax is :\n",
    "\n",
    "``Dense(number_of_neurons, activation = 'tanh')``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add a fully connected layer with 128 neurons and a relu activation function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a **dropout** layer which randomly **removes 40%** of the previous layer's neurons.\n",
    "\n",
    "Syntax is :\n",
    "\n",
    "``Dropout(0.3)``  (This removes 30% of the previous neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add a dropout layer which randomly removes 40% of the neurons of the previous layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the classification layer.\n",
    "\n",
    "In a neural network, the classification layer is nothing more than **a fully connected layer with a number of neurons equal to the number of classes** and a **'softmax' activation function**.\n",
    "\n",
    "Our classes are digits from 0 to 9 so we have 10 different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Add the classification layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compile the neural network.\n",
    "\n",
    "**What does compile do?**\n",
    "\n",
    "Compile defines the loss function, the optimizer and the metrics. That's all.\n",
    "You need a compiled model to train the neural network (because training uses the loss function and the optimizer).\n",
    "\n",
    "|||\n",
    "|:-|:-|\n",
    "|**loss function**|function that computes the error we want to minimize. There are different ways to mathematically express errors. <br>The loss function allows us to choose which one we want to use|\n",
    "|**optimizer**|Types of optimization algorithms used in neural networks that allow to converge faster. In other words, the optimizer allows to reduce the number of iterations a neural networks needs to do before having good performance|\n",
    "|**metrics**|Allows to choose what metrics we want to display to follow the improvement of our neural network. For example, the accuracy is a metric. Accuracy is defined by the number of correctly predicted samples divided by the number of samples|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adam(), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of our neural network. Syntax is :\n",
    "\n",
    "> ``your_model_name.summary()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Display a summary of our convolutional neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the neural network for **10** epochs:\n",
    "<br>One epoch is when an **entire dataset** is passed through the neural network ONCE.\n",
    "\n",
    "To train the neural network use the ``fit`` function. The syntax is :\n",
    "\n",
    "``history = your_model_name.fit(training_samples_inputs, training_samples_outputs,\n",
    "          epochs=number_of_epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(test_samples_inputs, test_samples_outputs))``\n",
    "          \n",
    "The ``verbose = 1`` argument allows us to display the progress of the training, which is important to track if our neural network is improving or not.\n",
    "\n",
    "We store the training results in a variable (``history``) because we will want to make some plots with those results after the training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------------------TO DO-------------------------\n",
    "# Train the neural network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training of the network, the most important thing to follow is loss and accuracy on the training and validation sets.\n",
    "\n",
    "Let's plot the training loss and accuracy as well as the validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = list(range(1,len(history.history['accuracy'])+1))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(x_values, history.history['accuracy'])\n",
    "plt.plot(x_values, history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(x_values, history.history['loss'])\n",
    "plt.plot(x_values, history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike accuracy, loss is not a percentage. It is a summation of the errors made for each example in training or validation sets. **The lower the validation loss, the better a model**.\n",
    "\n",
    "Usually, as we keep adding epochs, the validation loss decreases at first and then starts to rise again.<br>\n",
    "**&#8594; the rule of thumb is to choose a number of epochs such as the training ends right before the validation loss starts increasing again**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats ! you have successfully built a Convolutional Neural Network capable of recognizing handwritten digits 98% of the time !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/l3q2XhfQ8oCkm1Ts4/giphy.gif\" width=\"500\" align=\"center\">\n",
    "\n",
    "Morgan Freeman is proud of you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our model. Pick a random image in the test set by picking a random number between 0 and 9999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "random_image_number = \n",
    "plt.imshow(x_test[random_image_number].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the predicted probabilities for our random image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_probabilities = model.predict(np.expand_dims(x_test[random_image_number], axis=0))\n",
    "print(np.array_str(output_probabilities, precision=2, suppress_small=True))\n",
    "print(\"The predicted class is : \" + str(output_probabilities.argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using a pre-trained state of the art model\n",
    "\n",
    "Now we will show you what a state of the art convolutional neural network can do.\n",
    "\n",
    "For that purpose, we will use **YOLO's architecture**:\n",
    "\n",
    "> You only look once (YOLO) is a state-of-the-art, real-time object detection system.\n",
    "\n",
    "**YOLO v3 architecture has:**\n",
    "\n",
    ">Number of layers: 349 | Parameter count: 62,001,757 | Trained size: 263 MB |\n",
    "\n",
    "Run the code below to setup YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd \"./yolov3-tf2/checkpoints/\"\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://translead-public-data.s3-eu-west-1.amazonaws.com/dev/yolo+loaded+weights/yolov3.tf.data-00000-of-00001'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('yolov3.tf.data-00000-of-00001', 'wb').write(r.content)\n",
    "\n",
    "url = 'https://translead-public-data.s3-eu-west-1.amazonaws.com/dev/yolo+loaded+weights/yolov3.tf.index'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('yolov3.tf.index', 'wb').write(r.content)\n",
    "\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code. \n",
    "\n",
    "It will display an **upload button**. Click on it and import the images that you want to upload (you can import multiple images at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "uploader = widgets.FileUpload(multiple=True)\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code processes your images one by one and outputs the results for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd \"./yolov3-tf2\"\n",
    "data = uploader.value\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "from IPython.display import Image, display\n",
    "for item in data.values():\n",
    "    file_name = list(item.keys())[0]\n",
    "    f = open(file_name, 'wb')\n",
    "    f.write(item[\"content\"])\n",
    "    f.close()\n",
    "    !python detect.py --image $file_name\n",
    "    display(Image(filename='output.jpg'))\n",
    "    \n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for doing this workshop !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
